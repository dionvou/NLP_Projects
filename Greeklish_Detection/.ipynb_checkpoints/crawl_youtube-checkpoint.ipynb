{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Language detection\n",
    "1. Build a language detector (Greek/Greeklish/English/Other) using RegExps.\n",
    "2. Create a ground truth evaluation dataset and assess your classifier. (Hint: you are free to\n",
    "manually extract data from online sources.) This dataset will be submitted as a CSV named as\n",
    "gold.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Crawl YouTube for videos with Greek posts\n",
    "1. Apply your language detector to the page’s title.\n",
    "2. Parse all the comments of the page but only if the title is in Greek/Greeklish.\n",
    "3. Use a strategy to jump to other pages that *will likely* have Greek/Greeklish titles.\n",
    "4. Form a CSV with the crawled information, to be submitted named as crawl.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries for crawling\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "#!pip3 install --user selenium\n",
    "#!pip3 install webdriver-manager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Firefox\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "greek        326\n",
       "english      282\n",
       "greeklish    221\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = pd.read_csv('gold.csv')\n",
    "gold['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we will build the function that detect language with regular expressions. This cant be accurate, since there is no way to distinguise greeklish from english. We will consider greeklish, everything that has a mix of greek and english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    \"\"\"\n",
    "    detect_language function parse a text and return if its greek/greeklish/english/other\n",
    "    based on regular expressions. \n",
    "\n",
    "    :str text: the str to check the language of it.\n",
    "    \n",
    "    :return: 0 if text is greek\n",
    "             1 if text is greeklish\n",
    "             2 if text is english\n",
    "             3 if text is other language\n",
    "    \"\"\" \n",
    "    #punctuation string\n",
    "    punc = '-._!\\\"`\\'#%&,«»:;<>=@{}~\\$\\(\\)\\*\\+\\/\\\\\\?\\[\\]\\^\\|'\n",
    "    # Creating a regular expression pattern to match Greek characters,toned characters,numbers,punctuation \n",
    "    #and space characters. The number of characters that must appear is the same as the text\n",
    "#     greek_expression = \"([\\u0370-\\u03ff\\u1f00-\\u1fff]|[Α-Ωα-ω0-9]|[ \\\\t\\\\n\\\\r\\\\f\\\\v]|[{}]){{{}}}\".format(punc,len(text))\n",
    "    greek_expression = r\"[\\u0370-\\u03ff\\u1f00-\\u1fffΑ-Ωα-ω0-9\" + re.escape(punc) + r\"\\s]{\" + str(len(text)) + r\"}\"\n",
    "    greek_pattern = re.compile(greek_expression, re.UNICODE)\n",
    "    match = greek_pattern.search(text)\n",
    "    if match is not None:\n",
    "        return 0\n",
    "    # Creating a regular expression pattern to match English characters,numbers,punctuation and space characters.\n",
    "    #The number of characters that must appear is the same as the text\n",
    "#     english_expression = \"([A-Za-z0-9]|[ \\\\t\\\\n\\\\r\\\\f\\\\v]|[{}]){{{}}}\".format(punc,len(text))\n",
    "    english_expression = r\"[A-Za-z0-9\" + re.escape(punc) + r\"\\s]{\" + str(len(text)) + r\"}\"\n",
    "    enlgish_pattern = re.compile(english_expression, re.UNICODE)\n",
    "    match = enlgish_pattern.search(text)\n",
    "    if match is not None:\n",
    "        return 2\n",
    "    # Creating a regular expression pattern to match Greek characters,toned characters,numbers,punctuation,\n",
    "    #space characters and english characters.The number of characters that must appear is the same as the text\n",
    "    #But it cant be only greek, or only english, because they would have been already catched above.\n",
    "    greeklish_expression = r\"[\\u0370-\\u03ff\\u1f00-\\u1fffΑ-Ωα-ω0-9A-Za-z\" + re.escape(punc) + r\"\\s]{\" + str(len(text)) + r\"}\"\n",
    "    #     greeklish_expression = \"([\\u0370-\\u03ff\\u1f00-\\u1fff]|[Α-Ωα-ω0-9]|[A-Za-z0-9]|[ \\\\t\\\\n\\\\r\\\\f\\\\v]|[{}]){{{}}}\".format(punc,len(text))\n",
    "    greeklish_pattern = re.compile(greeklish_expression, re.UNICODE)\n",
    "    match = greeklish_pattern.search(text)\n",
    "    if match is not None:\n",
    "        return 1\n",
    "    #if nothing of the above\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use our language detector to find the language for each text of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "for text in gold['text']:\n",
    "    result_list.append(detect_language(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detector returns integers from 0 to 3, so we need to map them to language names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our language detector found 366 out of 829 right languages\n"
     ]
    }
   ],
   "source": [
    "# Mapping dictionary\n",
    "mapping = {0: 'greek', 1: 'greeklish', 2: 'english', 3: 'other'}\n",
    "\n",
    "# Use a list comprehension to create a new array with the mapped values\n",
    "result = np.array([mapping[value] for value in result_list])\n",
    "\n",
    "found_right = (result==gold['language']).sum()\n",
    "print(f'Our language detector found {found_right} out of {gold.shape[0]} right languages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It didnt do well, because as we said before, it cant classify well greeklish language. For example, below we see a greek text, classified as greeklish. Which is not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to detect language: Booyah χαίρομαι παρά πολύ που ανοίχτηκες και τα έβγαλες όλα από μέσα σου και είσαι καλά. Ήρθε η ώρα για μια αλλαγή.\n",
      "Detected language is: greeklish\n"
     ]
    }
   ],
   "source": [
    "print(f'Text to detect language: {gold.text[17]}')\n",
    "print(f'Detected language is: {mapping[detect_language(gold.text[17])]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets crawl youtube. We will start from a greek video, grab the comments and go to the next one, from the proposed video that youtube give us. If it is greek we will crawl its comment. If not we will try the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(driver,url,data,id_):\n",
    "    \"\"\"\n",
    "    crawl is a function that start crawling the title and comments from a specific youtube video and returns \n",
    "    the url of the first proposed video along with the data.\n",
    "    \n",
    "    :param driver: the webdriver to use for crawling.\n",
    "    :param url: str youtube link, from which we crawl data.\n",
    "    :param data: dataframe with data.columns = ['text','id','parent_id','url','date']\n",
    "    \n",
    "    :return str: url of the next page to crawl.\n",
    "    :return dataframe: dataframe with data.columns = ['text','id','parent_id','url','date']\n",
    "    \"\"\" \n",
    "    \n",
    "    #string to add to the one that we will crawl. (because we crawl only the ending)\n",
    "    string ='https://www.youtube.com'\n",
    "    \n",
    "    driver.get(url)\n",
    "    next_page_url=''\n",
    "    \n",
    "    #open maximum size of browser window\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    #wait for page to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Scroll down 10 times; adjust as needed\n",
    "    for _ in range(10):  \n",
    "            driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "            time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    # Wait for comments to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #crawl html for beautiful soup\n",
    "    html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    \n",
    "    #parse title\n",
    "    title = soup.find(\"div\", {\"id\":'title',\"class\":\"style-scope ytd-watch-metadata\"}).text.strip()\n",
    "    \n",
    "    #parse date\n",
    "    info = soup.find('yt-formatted-string',{'id':'info'}).text.strip()\n",
    "    date_info = ''.join(str(x+' ') for x in info.split()[2:5])\n",
    "    \n",
    "    print(f'Title: {title}')\n",
    "    print(f'Date: {date_info}')\n",
    "    \n",
    "    #parse comments\n",
    "    comments = soup.find_all(\"yt-formatted-string\", {\"id\":'content-text'})\n",
    "    \n",
    "    #parse dates\n",
    "    dates = soup.find_all(\"yt-formatted-string\", {\"class\":'published-time-text style-scope ytd-comment-renderer'})\n",
    "     \n",
    "    \n",
    "    #if the video is greek/greeklish, crawl the comments, else jump to next video\n",
    "    if(detect_language(title)<2):\n",
    "        new_row = {'text': title.strip(), 'id': id_, 'parent_id': '0','url':url,'date':date_info}\n",
    "        data = data.append(new_row, ignore_index=True)\n",
    "        for i in range(len(comments)):\n",
    "            new_row = {'text': comments[i].text.strip(), 'id': '0', 'parent_id': id_,'url':'','date':dates[i].text}\n",
    "            data = data.append(new_row, ignore_index=True)\n",
    "    else:\n",
    "        print('The title is not in greek/greeklish, go to next video.')\n",
    "        \n",
    "    #parse 10 of the related videos    \n",
    "    urls = soup.find_all(\"a\",{\"class\":\"yt-simple-endpoint style-scope ytd-compact-video-renderer\"},limit=10)\n",
    "    texts = soup.find_all('span',{\"id\":'video-title'},limit=10)\n",
    "    \n",
    "    # go to a video that you have not parse before\n",
    "    for i in range(1,len(texts)):\n",
    "        if data['text'].str.contains(texts[i].text.strip()).any():\n",
    "            continue\n",
    "        else:\n",
    "            next_page_url = string+urls[i].get('href').strip()\n",
    "            break\n",
    "     \n",
    "    return next_page_url,data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run to 20 youtube videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current firefox version is 120.0\n",
      "[WDM] - Get LATEST geckodriver version for 120.0 firefox\n",
      "[WDM] - Driver [C:\\Users\\dionysis\\.wdm\\drivers\\geckodriver\\win64\\v0.33.0\\geckodriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ο Νίκος Μιχαλολιάκος στον ΣΚΑΪ\n",
      "Date: 11 years ago \n",
      "Comments crawled: 201\n",
      "Next video url: https://www.youtube.com/watch?v=WLequgheuYo\n",
      "Title: Ευθέως με τον Βασίλη Λεβέντη  - 09/01/2014\n",
      "Date: 9 years ago \n",
      "Comments crawled: 202\n",
      "Next video url: https://www.youtube.com/watch?v=x7MSXPRB4hE\n",
      "Title: Στον Ενικό - Βασίλης Λεβέντης - 28.9.2015\n",
      "Date: 8 years ago \n",
      "Comments crawled: 234\n",
      "Next video url: https://www.youtube.com/watch?v=fr7SSEj-d_I\n",
      "Title: Στον Ενικό - Άδωνις Γεωργιάδης - 5.10.2015\n",
      "Date: 8 years ago \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dionysis\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments crawled: 264\n",
      "Next video url: https://www.youtube.com/watch?v=b_6KFrKOznA\n",
      "Title: O Άδωνις Γεωργιάδης στο μάθημα της Ιστορίας για την Μακεδονία και τον Φίλιππο (1ο μέρος)\n",
      "Date: 5 years ago \n",
      "Comments crawled: 265\n",
      "Next video url: https://www.youtube.com/watch?v=jPVnHTpGTxw\n",
      "Title: ΜΑΘΗΜΑΤΑ ΙΣΤΟΡΙΑΣ - ΒΥΖΑΝΤΙΟ\n",
      "Date: 5 years ago \n",
      "Comments crawled: 320\n",
      "Next video url: https://www.youtube.com/watch?v=Gy11gPAD8nQ\n",
      "Title: Μαθήματα Ιστορίας | Μ. Αλέξανδρος, υϊός Διός\n",
      "Date: 1 year ago \n",
      "Comments crawled: 380\n",
      "Next video url: https://www.youtube.com/watch?v=ia0R29d_M_g\n",
      "Title: Μαθήματα Ιστορίας: Η ΓΕΝΝΗΣΗ ΤΗΣ ΡΩΜΑΪΚΗΣ ΑΥΤΟΚΡΑΤΟΡΙΑΣ\n",
      "Date: 4 years ago \n",
      "The title is not in greek/greeklish, go to next video.\n",
      "Comments crawled: 380\n",
      "Next video url: https://www.youtube.com/watch?v=grXt-2yspYc\n",
      "Title: Η δημιουργία της σύγχρονης Ιαπωνίας: Η ιστορία μιας αυτοκρατορίας | καθ. Μαρία Ευθυμίου\n",
      "Date: 10 months ago \n",
      "Comments crawled: 438\n",
      "Next video url: https://www.youtube.com/watch?v=cy93fFnSmAo\n",
      "Title: Ο Κυριάκος Πιερρακάκης με τη Μαρία Ευθυμίου στο «The Power of Innovation» του Fortune Greece\n",
      "Date: 9 months ago \n",
      "Comments crawled: 466\n",
      "Next video url: https://www.youtube.com/watch?v=sCjQHawxmZ0\n"
     ]
    }
   ],
   "source": [
    "#Build dataframe to put youtubes data\n",
    "columns = ['text','id','parent_id','url','date']\n",
    "data = pd.DataFrame(columns=columns)\n",
    "\n",
    "#give a specific url (should be a greek video)\n",
    "url = 'https://www.youtube.com/watch?v=pxOwSYgRPPU&ab_channel=SKAI.gr'\n",
    "\n",
    "#initialize driver, drivermanager will install the executable file\n",
    "driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "#id of each video\n",
    "id_=1\n",
    "#crawl to 5 videos\n",
    "for i in range(10):\n",
    "    url,data = crawl(driver,url,data,id_)\n",
    "    id_+=1\n",
    "    print(f'Comments crawled: {data.shape[0]}')\n",
    "    print(f'Next video url: {url}')\n",
    "    \n",
    "#close browser   \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ο Νίκος Μιχαλολιάκος στον ΣΚΑΪ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.youtube.com/watch?v=pxOwSYgRPPU&amp;ab...</td>\n",
       "      <td>11 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Αν ο Μπογδανος φορουσε την κουστουμια του Μηχα...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>8 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ο Μπογδανος πρέπει να διδάσκεται στις δραματικ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>3 months ago (edited)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>έχω πεθάνει απο τα γέλια με την όλη φάση</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>10 years ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Το κοντρόλ έχει πάρει φωτιά σε αυτό το επεισόδ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>5 years ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text id parent_id  \\\n",
       "0                     Ο Νίκος Μιχαλολιάκος στον ΣΚΑΪ  1         0   \n",
       "1  Αν ο Μπογδανος φορουσε την κουστουμια του Μηχα...  0         1   \n",
       "2  Ο Μπογδανος πρέπει να διδάσκεται στις δραματικ...  0         1   \n",
       "3           έχω πεθάνει απο τα γέλια με την όλη φάση  0         1   \n",
       "4  Το κοντρόλ έχει πάρει φωτιά σε αυτό το επεισόδ...  0         1   \n",
       "\n",
       "                                                 url                   date  \n",
       "0  https://www.youtube.com/watch?v=pxOwSYgRPPU&ab...          11 years ago   \n",
       "1                                                               8 years ago  \n",
       "2                                                     3 months ago (edited)  \n",
       "3                                                              10 years ago  \n",
       "4                                                               5 years ago  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
